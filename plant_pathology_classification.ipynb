{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492ff6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "import keras.optimizers as optimizers\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a923eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcbeffb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  healthy  multiple_diseases  rust  scab\n",
       "0  Train_0        0                  0     0     1\n",
       "1  Train_1        0                  1     0     0\n",
       "2  Train_2        1                  0     0     0\n",
       "3  Train_3        0                  0     1     0\n",
       "4  Train_4        1                  0     0     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb4f86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full['image_id']=data_full['image_id']+'.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c9a461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train_0.jpg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full['image_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817b176a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 1821)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(data_full.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "217afc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data_full, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf895991",
   "metadata": {},
   "source": [
    "# Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5a18b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1821/1821 [00:37<00:00, 48.24it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dir = '/Users/pawelpawlus/Documents/asseco/plant_pathology_classification/images/Train/'\n",
    "image_size = tuple((300,300))\n",
    "x = []\n",
    "for i in tqdm(range(data_full.shape[0])):\n",
    "    img = image.load_img(train_dir + data_full['image_id'][i]+'.jpg',color_mode='rgb',target_size=image_size)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    x.append(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d00201cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/pawelpawlus/Documents/asseco/plant_pathology_classification/images/Train/'\n",
    "image_size = 300\n",
    "batch_size = 1\n",
    "\n",
    "train_data_gen = image.ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=.5,\n",
    "    rescale=1/255,\n",
    "    fill_mode='nearest',\n",
    "    shear_range=0.1,\n",
    "    brightness_range=[0.5, 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29ec81bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = train_data_gen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    train_dir,\n",
    "    target_size=(image_size,image_size),\n",
    "    x_col = 'image_id',\n",
    "    y_col = ['healthy','multiple_diseases','rust','scab'],\n",
    "    class_mode = 'raw',\n",
    "    shuffle=False,\n",
    "    subset='training',\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74e2ba7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 300, 300, 3), (1, 4))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next()[0].shape,train_generator.next()[1].shape\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a41af36",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50e0cbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "l=0\n",
    "for batch in train_data_gen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    train_dir,\n",
    "    target_size=(image_size,image_size),\n",
    "    x_col = 'image_id',\n",
    "    y_col = ['healthy','multiple_diseases','rust','scab'],\n",
    "    class_mode = 'raw',\n",
    "    shuffle=False,\n",
    "    subset='training',\n",
    "    batch_size=batch_size,\n",
    "    save_to_dir='/Users/pawelpawlus/Documents/asseco/plant_pathology_classification/preview',\n",
    "    save_format='jpeg',\n",
    "    save_prefix='train'):\n",
    "    l+=1\n",
    "    if l < 5:\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1509525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 365 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "val_generator = train_data_gen.flow_from_dataframe(\n",
    "    val_data,\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    x_col = 'image_id',\n",
    "    y_col = ['healthy','multiple_diseases','rust','scab'],\n",
    "    class_mode = 'raw',\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba36bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "LR_reduce=ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                            factor=.5,\n",
    "                            patience=10,\n",
    "                            min_lr=.000001,\n",
    "                            verbose=1)\n",
    "\n",
    "ES_monitor=EarlyStopping(monitor='val_loss',\n",
    "                          patience=20)\n",
    "\n",
    "reg = .0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0b23a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf296c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14652a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13c4cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3054f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.array(data_full.drop(['image_id'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "171da511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,x_test,y_train,y_test = train_test_split(X,y, random_state = 20, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb298a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "543344e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\", input_shape=(300,300,3), border_mode ='same'))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\", border_mode='same'))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv2D(filters=32, kernel_size=(5, 5), activation=\"relu\",  border_mode ='same'))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv2D(filters=8, kernel_size=(5, 5), activation=\"relu\", border_mode='same'))\n",
    "\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv2D(filters=8, kernel_size=(5, 5), activation=\"relu\", border_mode='same'))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8eb4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.regularizers  import l2\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(5,5),activation='relu', input_shape=(300, 300, 3), kernel_regularizer=l2(reg)))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(Conv2D(128, kernel_size=(5,5),activation='relu', kernel_regularizer=l2(reg)))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\n",
    "# model.add(Dropout(.25))\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=(3,3),activation='relu', kernel_regularizer=l2(reg)))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(Conv2D(128, kernel_size=(3,3),activation='relu',kernel_regularizer=l2(reg)))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\n",
    "# model.add(Dropout(.25))\n",
    "\n",
    "\n",
    "# model.add(Conv2D(128, kernel_size=(5,5),activation='relu', kernel_regularizer=l2(reg)))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(Conv2D(512, kernel_size=(5,5),activation='relu',kernel_regularizer=l2(reg)))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\n",
    "# model.add(Dropout(.25))\n",
    "\n",
    "# model.add(Conv2D(128, kernel_size=(3,3),activation='relu',kernel_regularizer=l2(reg)))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(Conv2D(512, kernel_size=(3,3),activation='relu',kernel_regularizer=l2(reg)))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\n",
    "# model.add(Dropout(.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(300,activation='relu'))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(Dropout(.25))\n",
    "# model.add(Dense(200,activation='relu'))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(Dropout(.25))\n",
    "# model.add(Dense(100,activation='relu'))\n",
    "# model.add(BatchNormalization(axis=-1,center=True,scale=False))\n",
    "# model.add(Dropout(.25))\n",
    "# model.add(Dense(4,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae3a976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(300,300,3),activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0253884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(GlobalAveragePooling2D(input_shape =(300,300,3)))\n",
    "\n",
    "# #model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1745a7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 300, 300, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 298, 298, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1420864)           0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                22733840  \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 22,753,300\n",
      "Trainable params: 22,753,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f9cea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "001ddd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5916aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "15/91 [===>..........................] - ETA: 9:02 - loss: 2.0087 - accuracy: 0.3625"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-69d7654c65b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                              \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                               callbacks=[LR_reduce,ES_monitor])\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = model.fit_generator(train_generator,epochs=150,\n",
    "                              steps_per_epoch=train_generator.n//batch_size,\n",
    "                              validation_data=val_generator,\n",
    "                             validation_steps=val_generator.n//batch_size,\n",
    "                              verbose = 1,\n",
    "                              callbacks=[LR_reduce,ES_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9108f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(x_train,y_train, epochs=10,batch_size=16, validation_data=(x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
